{
  "AveragePool": {
    "name": "AveragePoolNode",
    "input": {
      "X": {
        "type": "Tensor",
        "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
      }
    },
    "parameters": {
      "kernel_size": {
        "type": "list of ints",
        "description": "The size of the kernel along each axis.",
        "required": "true",
        "default": "1, 1"
      },
      "stride": {
        "type": "list of ints",
        "description": "Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.",
        "required": "false",
        "default": "1, 1"
      },
      "padding": {
        "type": "list of ints",
        "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.",
        "required": "false",
        "default": "1, 1"
      },
      "ceil_mode": {
        "type": "boolean",
        "description": "Whether to use ceil or floor (default) to compute the output shape.",
        "required": "false",
        "default": "false"
      },
      "count_include_pad": {
        "type": "boolean",
        "description": "Whether include pad pixels when calculating values for the edges. Default is 0, doesn't count include pad.",
        "required": "false",
        "default": "false"
      }
    },
    "output": {
      "Y": {
        "type": "Tensor",
        "description": "Output data tensor from average or max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Floor value of the dimension is used."
      }
    },
    "description": "Consumes an input tensor X and applies average pooling across the tensor according to kernel sizes, stride sizes, and pad lengths. It consists of computing the average on all values of a subset of the input tensor according to the kernel size and downsampling the data into the output tensor Y for further processing."
  },
  "Batch Normalization": {
    "name": "BatchNormNode",
    "input": {
      "X": {
        "type": "Tensor",
        "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1."
      }
    },
    "parameters": {
      "num_features": {
        "type": "int",
        "description": "Number of features of the node.",
        "required": "true",
        "default": "1"
      },
      "weight": {
        "type": "Tensor",
        "description": "Scale tensor of shape (C).",
        "required": "true",
        "shape": "num_features"
      },
      "bias": {
        "type": "Tensor",
        "description": "Bias tensor of shape (C).",
        "required": "true",
        "shape": "num_features"
      },
      "running_mean": {
        "type": "Tensor",
        "description": "running (training) or estimated (testing) mean tensor of shape (C).",
        "required": "true"
      },
      "running_var": {
        "type": "Tensor",
        "description": "running (training) or estimated (testing) variance tensor of shape (C).",
        "required": "true"
      },
      "eps": {
        "type": "float",
        "description": "The epsilon value to use to avoid division by zero.",
        "required": "false",
        "default": "1e-05"
      },
      "momentum": {
        "type": "float",
        "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum).",
        "required": "false",
        "default": "0.9"
      },
      "affine": {
        "type": "boolean",
        "description": "affine",
        "required": "false",
        "default": "true"
      },
      "track_running_stats": {
        "type": "boolean",
        "description": "a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and uses batch statistics instead in both training and eval modes if the running mean and variance are None",
        "required": "false",
        "default": "true"
      }
    },
    "output": {
      "Y": {
        "type": "Tensor",
        "description": "The output tensor of the same shape as X"
      }
    },
    "description": "Carries out batch normalization. Depending on the mode it is\nbeing run, there are multiple cases for the number of outputs."
  },
  "Convolutional": {
    "name": "ConvNode",
    "input": {
      "X": {
        "type": "Tensor",
        "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
      }
    },
    "parameters": {
      "in_channels": {
        "type": "int",
        "description": "Number of input channels in Conv Layer."
      },
      "out_channels": {
        "type": "int",
        "description": "Number of output channels in Conv Layer."
      },
      "kernel_size": {
        "type": "list of ints",
        "description": "The shape of the convolution kernel. If not present, should be inferred from input W.",
        "required": "false",
        "default": "1, 1"
      },
      "stride": {
        "type": "list of ints",
        "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis.",
        "required": "false",
        "default": "1, 1"
      },
      "padding": {
        "type": "list of ints",
        "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.",
        "required": "false",
        "default": "1, 1"
      },
      "dilation": {
        "type": "list of ints",
        "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis.",
        "required": "false",
        "default": "1, 1"
      },
      "groups": {
        "type": "int",
        "description": "number of groups input channels and output channels are divided into.",
        "required": "true",
        "default": "1"
      },
      "bias": {
        "type": "Tensor",
        "description": "Optional 1D bias to be added to the convolution, has size of M.",
        "required": "true",
        "shape": "out_channels"
      },
      "weight": {
        "type": "Tensor",
        "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based indices for the shape array). Or in other words FILTER_IN_CHANNEL should be equal to DATA_CHANNEL.",
        "required": "true",
        "shape": "out_channels, in_channels, kernel_size"
      }
    },
    "output": {
      "Y": {
        "type": "Tensor",
        "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
      }
    },
    "description": "Consumes an input tensor and a filter, and computes the output."
  },
  "Dropout": {
    "name": "DropoutNode",
    "input": {
      "data": {
        "type": "Tensor",
        "description": "The input data as Tensor."
      }
    },
    "parameters": {
      "p": {
        "type": "float",
        "description": "The probability of an element to be zeroed",
        "required": "false",
        "default": "0.5"
      }
    },
    "output": {
      "output": {
        "type": "Tensor",
        "description": "Output tensor."
      }
    },
    "description": "It takes an input floating-point tensor, an optional input ratio (floating-point scalar) and an optional input training_mode (boolean scalar). It produces two tensor outputs, output (floating-point tensor) and mask (optional Tensor<bool>). If training_mode is true then the output Y will be a random dropout."
  },
  "Flatten": {
    "name": "FlattenNode",
    "input": {
      "A": {
        "type": "Tensor",
        "description": "A tensor of rank >= axis."
      }
    },
    "parameters": {
      "axis": {
        "type": "int",
        "description": "Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output.",
        "required": "false",
        "default": "0"
      }
    },
    "output": {
      "output": {
        "type": "Tensor",
        "description": "A 2D tensor with the contents of the input tensor, with input dimensions up to axis flattened to the outer dimension of the output and remaining input dimensions flattened into the inner dimension of the output."
      }
    },
    "description": "Flattens the input tensor into a 2D matrix. If input tensor has shape (d_0, d_1, ... d_n),\nthen the output will have shape (d_0 X d_1 ... d_(axis-1), d_axis X d_(axis+1) ... X dn)."
  },
  "Fully Connected": {
    "name": "FullyConnectedNode",
    "input": {
      "A": {
        "type": "Tensor",
        "description": "Input tensor."
      }
    },
    "parameters": {
      "in_features": {
        "type": "int",
        "description": "Number of inputs of the layer."
      },
      "out_features": {
        "type": "int",
        "description": "Number of outputs of the layer."
      },
      "weight": {
        "type": "Tensor",
        "description": "Weight tensor.",
        "shape": "out_features, in_features"
      },
      "bias": {
        "type": "Tensor",
        "description": "Bias tensor.",
        "shape": "out_features"
      }
    },
    "output": {
      "output": {
        "type": "Tensor",
        "description": "Output tensor."
      }
    },
    "description": "Matrix product that computes alpha * A' * B' + bias"
  },
  "LRN": {
    "name": "LRNNode",
    "input": {
      "X": {
        "type": "Tensor",
        "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
      }
    },
    "parameters": {
      "size": {
        "type": "int",
        "description": "The number of channels to sum over.",
        "required": "true"
      },
      "alpha": {
        "type": "float",
        "description": "Scaling parameter.",
        "required": "false",
        "default": "0.0001"
      },
      "beta": {
        "type": "float",
        "description": "The exponent.",
        "required": "false",
        "default": "0.75"
      },
      "k": {
        "type": "float",
        "description": "Additive factor",
        "required": "false",
        "default": "1.0"
      }
    },
    "output": {
      "Y": {
        "type": "Tensor",
        "description": "Output tensor, which has the shape and type as input tensor."
      }
    },
    "description": "Local Response Normalization proposed in the AlexNet paper. It normalizes over local input regions. The local region is defined across the channels. For an element X[n, c, d1, ..., dk] in a tensor of shape (N x C x D1 x D2, ..., Dk), its region is {X[n, i, d1, ..., dk] | max(0, c - floor((size - 1) / 2)) <= i <= min(C - 1, c + ceil((size - 1) / 2))}."
  },
  "MaxPool": {
    "name": "MaxPoolNode",
    "input": {
      "X": {
        "type": "Tensor",
        "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
      }
    },
    "parameters": {
      "kernel_size": {
        "type": "list of ints",
        "description": "The size of the kernel along each axis.",
        "required": "true",
        "default": "1, 1"
      },
      "stride": {
        "type": "list of ints",
        "description": "Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.",
        "default": "1, 1"
      },
      "padding": {
        "type": "list of ints",
        "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.",
        "default": "1, 1"
      },
      "ceil_mode": {
        "type": "boolean",
        "description": "Whether to use ceil or floor (default) to compute the output shape.",
        "required": "false",
        "default": "0"
      },
      "dilation": {
        "type": "int",
        "description": "Dilation value along each spatial axis of filter. If not present, the dilation defaults to 1 along each spatial axis.",
        "required": "false",
        "default": "1"
      },
      "return_indices": {
        "type": "boolean",
        "description": "Determines if the operator has to return indices output.",
        "required": "false",
        "default": "false"
      }
    },
    "output": {
      "Y": {
        "type": "Tensor",
        "description": "Output data tensor from average or max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Floor value of the dimension is used."
      },
      "indices": {
        "type": "Tensor",
        "description": "Indices tensor from max pooling across the input tensor. The dimensions of indices are the same as output tensor. The values in indices of are the indices of the selected values during pooling. The indices are computed as flatten 1-D tensor, and the indices do not consider padding. So the values in indices are in [0, N x C x D1 x ... x Dn).",
        "optional": "true"
      }
    },
    "description": "MaxPool consumes an input tensor X and applies max pooling across the tensor according to kernel sizes, stride sizes, and pad lengths. max pooling consisting of computing the max on all values of a subset of the input tensor according to the kernel size and downsampling the data into the output tensor Y for further processing. "
  },
  "ReLu": {
    "name": "ReLUNode",
    "input": {
      "X": {
        "type": "Tensor",
        "description": "Input tensor."
      }
    },
    "parameters": {
    },
    "output": {
      "Y": {
        "type": "Tensor",
        "description": "Output tensor."
      }
    },
    "description": "Relu takes one input data (Tensor) and produces one output data (Tensor) where\nthe rectified linear function, y = max(0, x), is applied to the tensor elementwise."
  },
  "Reshape": {
    "name": "ReshapeNode",
    "input": {
      "data": {
        "type": "Tensor",
        "description": "An input tensor."
      }
    },
    "parameters": {
      "shape": {
        "type": "list of ints",
        "description": "Specified shape for output.",
        "required": "true",
        "default": "1, 1"
      },
      "allow_zero": {
        "type": "boolean",
        "description": "allowzero=1 indicates that if any value in the 'shape' input is set to zero.",
        "required": "false",
        "default": "0"
      }
    },
    "output": {
      "reshaped": {
        "type": "Tensor",
        "description": "Reshaped data."
      }
    },
    "description": "Reshape the input tensor similar to numpy.reshape. First input is the data tensor, second input is a shape tensor which specifies the output shape. It outputs the reshaped tensor. At most one dimension of the new shape can be -1. In this case, the value is inferred from the size of the tensor and the remaining dimensions. A dimension could also be 0, in which case the actual dimension value is unchanged (i.e. taken from the input tensor)."
  },
  "Sigmoid": {
    "name": "SigmoidNode",
    "input": {
      "X": {
        "type": "Tensor",
        "description": "Input tensor."
      }
    },
    "parameters": {
    },
    "output": {
      "Y": {
        "type": "Tensor",
        "description": "Output tensor."
      }
    },
    "description": "Sigmoid takes one input data (Tensor) and produces one output data (Tensor) where\nthe rectified linear function, y = max(0, x), is applied to the tensor elementwise."
  },
  "SoftMax": {
    "name": "SoftMaxNode",
    "input": {
      "X": {
        "type": "Tensor",
        "description": "Input tensor."
      }
    },
    "parameters": {
      "axis": {
        "type": "int",
        "description": " A dimension along which Softmax will be computed (so every slice along dim will sum to 1).",
        "required": "false",
        "default": "-1"
      }
    },
    "output": {
      "Y": {
        "type": "Tensor",
        "description": "Output tensor."
      }
    },
    "description": "The operator computes the normalized exponential values for the given input: Softmax(input, axis) = Exp(input) / ReduceSum(Exp(input), axis=axis, keepdims=1). The input does not need to explicitly be a 2D vector. The axis attribute indicates the dimension along which Softmax will be performed. The output tensor has the same shape and contains the Softmax values of the corresponding input."
  },
  "Unsqueeze": {
    "name": "UnsqueezeNode",
    "input": {
      "Data": {
        "type": "Tensor",
        "description": "Original tensor."
      }
    },
    "parameters": {
      "axes": {
        "type": "list of ints",
        "description": "List of integers indicating the dimensions to be inserted. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(expanded).",
        "default": "1, 1"
      }
    },
    "output": {
      "expanded": {
        "type": "Tensor",
        "description": "Reshaped tensor with same data as input."
      }
    },
    "description": "Insert single-dimensional entries to the shape of an input tensor (data). Takes one required input axes - which contains a list of dimension indices and this operator will insert a dimension of value 1 into the corresponding index of the output tensor (expanded)."
  }
}